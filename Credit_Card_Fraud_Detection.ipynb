{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Laxmikurapati/Machine-learning-Projects/blob/main/Credit_Card_Fraud_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#**Credit Card Faurd Detection**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![download (4).jpeg](data:image/jpeg;base64,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)\n"
      ],
      "metadata": {
        "id": "8MDpDI67jJqT"
      }
    },
    {
      "metadata": {
        "id": "ag78ROHKZBM3"
      },
      "cell_type": "markdown",
      "source": [
        "**Dataset link**: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vzq1eaPY1Fcx",
        "outputId": "5ca83526-5db7-4c6a-dc83-349945efc2bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "OaUh3UOJZBM4"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import warnings\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "yJlQcqeDZBM8"
      },
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('/content/creditcard.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "1OQf4SAGZBM9",
        "outputId": "5a7c9abe-4bb6-4d6f-cbf7-10e5c48ce8bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
              "1  0.125895 -0.008983  0.014724    2.69    0.0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66    0.0  \n",
              "3 -0.221929  0.062723  0.061458  123.50    0.0  \n",
              "4  0.502292  0.219422  0.215153   69.99    0.0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd109387-20cf-498f-8ff6-54501b93549a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd109387-20cf-498f-8ff6-54501b93549a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bd109387-20cf-498f-8ff6-54501b93549a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bd109387-20cf-498f-8ff6-54501b93549a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "igwgr2JjZBNC",
        "outputId": "036144cc-38f2-4d18-8437-1c246d5b4157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5974 entries, 0 to 5973\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Time    5974 non-null   int64  \n",
            " 1   V1      5974 non-null   float64\n",
            " 2   V2      5974 non-null   float64\n",
            " 3   V3      5974 non-null   float64\n",
            " 4   V4      5974 non-null   float64\n",
            " 5   V5      5974 non-null   float64\n",
            " 6   V6      5974 non-null   float64\n",
            " 7   V7      5974 non-null   float64\n",
            " 8   V8      5974 non-null   float64\n",
            " 9   V9      5974 non-null   float64\n",
            " 10  V10     5974 non-null   float64\n",
            " 11  V11     5974 non-null   float64\n",
            " 12  V12     5974 non-null   float64\n",
            " 13  V13     5974 non-null   float64\n",
            " 14  V14     5974 non-null   float64\n",
            " 15  V15     5974 non-null   float64\n",
            " 16  V16     5974 non-null   float64\n",
            " 17  V17     5974 non-null   float64\n",
            " 18  V18     5973 non-null   float64\n",
            " 19  V19     5973 non-null   float64\n",
            " 20  V20     5973 non-null   float64\n",
            " 21  V21     5973 non-null   float64\n",
            " 22  V22     5973 non-null   float64\n",
            " 23  V23     5973 non-null   float64\n",
            " 24  V24     5973 non-null   float64\n",
            " 25  V25     5973 non-null   float64\n",
            " 26  V26     5973 non-null   float64\n",
            " 27  V27     5973 non-null   float64\n",
            " 28  V28     5973 non-null   float64\n",
            " 29  Amount  5973 non-null   float64\n",
            " 30  Class   5973 non-null   float64\n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 1.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got no categorical Values, so we can continue without any onehot encoding or label encoding"
      ],
      "metadata": {
        "id": "qk5XDnXxt6my"
      }
    },
    {
      "metadata": {
        "trusted": true,
        "id": "60dgpi0CZBNF",
        "outputId": "33baa0a9-141c-4aea-ffc0-e2aae50ce59d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5974, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "X3cjJk8XZBNH",
        "outputId": "67aba3b1-ff59-47fe-d26e-77fa9f7be821",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
              "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
              "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
              "       'Class'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qaW4TgOt2cE",
        "outputId": "d7b79dd1-fa33-4b0e-b336-94226f554691"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time      0\n",
              "V1        0\n",
              "V2        0\n",
              "V3        0\n",
              "V4        0\n",
              "V5        0\n",
              "V6        0\n",
              "V7        0\n",
              "V8        0\n",
              "V9        0\n",
              "V10       0\n",
              "V11       0\n",
              "V12       0\n",
              "V13       0\n",
              "V14       0\n",
              "V15       0\n",
              "V16       0\n",
              "V17       0\n",
              "V18       1\n",
              "V19       1\n",
              "V20       1\n",
              "V21       1\n",
              "V22       1\n",
              "V23       1\n",
              "V24       1\n",
              "V25       1\n",
              "V26       1\n",
              "V27       1\n",
              "V28       1\n",
              "Amount    1\n",
              "Class     1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "Y_SNON-Rt2aC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2Vwf0iTt2Vd",
        "outputId": "411b42ef-711e-43ca-9751-98656d74a2b9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time      0\n",
              "V1        0\n",
              "V2        0\n",
              "V3        0\n",
              "V4        0\n",
              "V5        0\n",
              "V6        0\n",
              "V7        0\n",
              "V8        0\n",
              "V9        0\n",
              "V10       0\n",
              "V11       0\n",
              "V12       0\n",
              "V13       0\n",
              "V14       0\n",
              "V15       0\n",
              "V16       0\n",
              "V17       0\n",
              "V18       0\n",
              "V19       0\n",
              "V20       0\n",
              "V21       0\n",
              "V22       0\n",
              "V23       0\n",
              "V24       0\n",
              "V25       0\n",
              "V26       0\n",
              "V27       0\n",
              "V28       0\n",
              "Amount    0\n",
              "Class     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD39Y-bFt2Hu",
        "outputId": "ed8e0296-d70f-4aee-f06a-1d87439da0a4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    5970\n",
              "1.0       3\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "vtG__MNWZBNJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "0a1ce454-dbcc-43eb-d252-4af0cbe230e8"
      },
      "cell_type": "code",
      "source": [
        "label_size = [data['Class'].sum(), len(data['Class'])- data['Class'].sum()]\n",
        "plt.bar(['Fraud','Real'],label_size)\n",
        "print('Fraud Cases: {}'.format(len(data[data['Class'] == 1]))) \n",
        "print('Valid Transactions: {}'.format(len(data[data['Class'] == 0]))) \n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fraud Cases: 3\n",
            "Valid Transactions: 5970\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above analysis we can say that the dataset is imbalance so we got to balance the dataset\n"
      ],
      "metadata": {
        "id": "yv7Zzw_9tb2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=data.drop('Class',axis=1)\n",
        "y=data['Class']"
      ],
      "metadata": {
        "id": "XrXNO3W-wgNo"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
      ],
      "metadata": {
        "id": "yIlu4ma3wbHq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBaypCT5wpZM",
        "outputId": "243efb0b-613f-4eb0-f654-177ec4eb1037"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4778, 30)\n",
            "(4778,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building ANN Model in tenserflow/Keras**"
      ],
      "metadata": {
        "id": "TySB_srOvrm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons==0.16.1\n",
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuUZgJGqvpSv",
        "outputId": "7cd94066-0658-495b-c6d6-3677f66e1f94"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons==0.16.1\n",
            "  Downloading tensorflow_addons-0.16.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typeguard>=2.7 (from tensorflow-addons==0.16.1)\n",
            "  Downloading typeguard-4.0.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1) (4.5.0)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1 typeguard-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import confusion_matrix , classification_report"
      ],
      "metadata": {
        "id": "nGALK4AYvpOZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ANN(X_train, y_train, X_test, y_test, loss, weights):\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(26, input_dim=30, activation='relu'),\n",
        "        keras.layers.Dense(15, activation='relu'),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
        "    \n",
        "    if weights == -1:\n",
        "        model.fit(X_train, y_train, epochs=100)\n",
        "    else:\n",
        "        model.fit(X_train, y_train, epochs=100, class_weight = weights)\n",
        "    \n",
        "    print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "    y_preds = model.predict(X_test)\n",
        "    y_preds = np.round(y_preds)\n",
        "    \n",
        "    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
        "    \n",
        "    return y_preds"
      ],
      "metadata": {
        "id": "LGzlJhUlvpJl"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGefYVYcvpFA",
        "outputId": "9e430d8b-c81a-4a60-c902-53d8732bd6b9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "150/150 [==============================] - 1s 2ms/step - loss: 0.0421 - accuracy: 0.9985\n",
            "Epoch 2/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9996\n",
            "Epoch 3/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.9996\n",
            "Epoch 4/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 0.9990\n",
            "Epoch 5/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.9996\n",
            "Epoch 6/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.9996\n",
            "Epoch 7/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9994\n",
            "Epoch 8/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9996\n",
            "Epoch 9/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9994\n",
            "Epoch 10/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.9992\n",
            "Epoch 11/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9996\n",
            "Epoch 12/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 0.9996\n",
            "Epoch 13/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 0.9996\n",
            "Epoch 14/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.9996\n",
            "Epoch 15/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 0.9994\n",
            "Epoch 16/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 0.9996\n",
            "Epoch 17/100\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9994\n",
            "Epoch 18/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.9994\n",
            "Epoch 19/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.9994\n",
            "Epoch 20/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.9996\n",
            "Epoch 21/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9996\n",
            "Epoch 22/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 0.9996\n",
            "Epoch 23/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.9992\n",
            "Epoch 24/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9996\n",
            "Epoch 25/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.9996\n",
            "Epoch 26/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.9994\n",
            "Epoch 27/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.9998\n",
            "Epoch 28/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.9994\n",
            "Epoch 29/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9996\n",
            "Epoch 30/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.9998\n",
            "Epoch 31/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.9998\n",
            "Epoch 32/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.9996\n",
            "Epoch 33/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9998\n",
            "Epoch 34/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 8.7023e-04 - accuracy: 0.9998\n",
            "Epoch 35/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 8.4892e-04 - accuracy: 0.9998\n",
            "Epoch 36/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 4.0463e-04 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 5.5386e-04 - accuracy: 0.9998\n",
            "Epoch 38/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9994\n",
            "Epoch 39/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.9994\n",
            "Epoch 40/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9996\n",
            "Epoch 41/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 4.4687e-04 - accuracy: 0.9998\n",
            "Epoch 42/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 2.6820e-04 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9996\n",
            "Epoch 44/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.9998\n",
            "Epoch 45/100\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 2.3974e-04 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 2.2959e-04 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 4.8655e-04 - accuracy: 0.9998\n",
            "Epoch 48/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 3.1730e-04 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 1.5278e-04 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 1.7976e-04 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 1.4181e-04 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 1.0969e-04 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 1.1141e-04 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 1.0230e-04 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 56/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 0.9996\n",
            "Epoch 57/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.9996\n",
            "Epoch 58/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 0.9998\n",
            "Epoch 59/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.9994\n",
            "Epoch 60/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 0.9990\n",
            "Epoch 61/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9994\n",
            "Epoch 62/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.9996\n",
            "Epoch 63/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.9998\n",
            "Epoch 64/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.9996\n",
            "Epoch 65/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 5.2152e-04 - accuracy: 0.9998\n",
            "Epoch 66/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 4.0573e-04 - accuracy: 0.9998\n",
            "Epoch 67/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 2.3960e-04 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 1.9395e-04 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 1.9195e-04 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 1.7273e-04 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 5.3894e-04 - accuracy: 0.9996\n",
            "Epoch 72/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 8.3112e-04 - accuracy: 0.9996\n",
            "Epoch 73/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 0.9998\n",
            "Epoch 74/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 4.7841e-04 - accuracy: 0.9998\n",
            "Epoch 75/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.9992\n",
            "Epoch 76/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.9998\n",
            "Epoch 77/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 4.1635e-04 - accuracy: 0.9998\n",
            "Epoch 78/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 8.5056e-05 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 5.9514e-05 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 4.0902e-05 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 3.4700e-05 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 3.2480e-05 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 3.0332e-05 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 2.9840e-05 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 2.5895e-05 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 2.5295e-05 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 2.2823e-05 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 1.9847e-05 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 1.8416e-05 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 1.6756e-05 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 1.5763e-05 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 1.4063e-05 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 1.3149e-05 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 1.2810e-05 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 1.1173e-05 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 1.1051e-05 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 9.8764e-06 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 9.0995e-06 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 8.3849e-06 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 7.7089e-06 - accuracy: 1.0000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.9992\n",
            "[0.25023362040519714, 0.9991631507873535]\n",
            "38/38 [==============================] - 0s 2ms/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      1194\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           1.00      1195\n",
            "   macro avg       0.50      0.50      0.50      1195\n",
            "weighted avg       1.00      1.00      1.00      1195\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_preds)\n",
        "print('Confusion matrix:\\n', conf_mat)\n",
        "\n",
        "labels = ['Class 0', 'Class 1']\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(conf_mat, cmap=plt.cm.Blues)\n",
        "fig.colorbar(cax)\n",
        "ax.set_xticklabels([''] + labels)\n",
        "ax.set_yticklabels([''] + labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Expected')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "cl_uMhqlvpAJ",
        "outputId": "3832c372-f842-4cb6-ce46-58d692091344"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[1194    0]\n",
            " [   1    0]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mitigating Skewdness of Data**"
      ],
      "metadata": {
        "id": "AIKor_EbtlZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A widely adopted technique for dealing with highly unbalanced datasets is called resampling. It consists of removing samples from the majority class (under-sampling) and / or adding more examples from the minority class (over-sampling).\n",
        "\n",
        "![download (6).png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "\n",
        "Despite the advantage of balancing classes, these techniques also have their weaknesses (there is no free lunch). The simplest implementation of over-sampling is to duplicate random records from the minority class, which can cause overfitting. In under-sampling, the simplest technique involves removing random records from the majority class, which can cause loss of information."
      ],
      "metadata": {
        "id": "tev_tdol0nIp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Method-1 : Under Sampling**"
      ],
      "metadata": {
        "id": "wOhTDXhw25q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Class count\n",
        "count_class_0, count_class_1 = data.Class.value_counts()\n",
        "\n",
        "# Divide by class\n",
        "df_class_0 = data[data['Class'] == 0]\n",
        "df_class_1 = data[data['Class'] == 1]\n",
        "print(\"Number of Safe transactions: \",len(df_class_0))\n",
        "print(\"Number of fraud transactions: \",len(df_class_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm5FEykc0m2k",
        "outputId": "9882960a-daaf-4a68-cdd1-6dae56175243"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Safe transactions:  5970\n",
            "Number of fraud transactions:  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Undersample 0-class and concat the DataFrames of both class\n",
        "df_class_0_under = df_class_0.sample(count_class_1)\n",
        "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
        "\n",
        "print('Random under-sampling:')\n",
        "print(df_test_under.Class.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hymt3Y3J0mxo",
        "outputId": "469cdbb7-13f1-491c-8eb7-294f20598b66"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random under-sampling:\n",
            "0.0    3\n",
            "1.0    3\n",
            "Name: Class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no use of performing undersampling as the data is very sample contaning only 3 samples "
      ],
      "metadata": {
        "id": "zavG2RjZ2vXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Method- 2: Oversampling**"
      ],
      "metadata": {
        "id": "5CjDc3D-7kmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Oversample 1-class and concat the DataFrames of both classes\n",
        "df_class_1_over = df_class_1.sample(count_class_0, replace=True)\n",
        "df_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
        "\n",
        "print('Random over-sampling:')\n",
        "print(df_test_over.Class.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKLni4qU0msl",
        "outputId": "bab00ad0-0948-4e6a-bd2c-a9b29be5ffc5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random over-sampling:\n",
            "0.0    5970\n",
            "1.0    5970\n",
            "Name: Class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_test_over.drop('Class',axis='columns')\n",
        "y = df_test_over['Class']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
      ],
      "metadata": {
        "id": "LEjwU9lQ0mnu"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of classes in training Data\n",
        "y_train.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqI1TFAf0mlF",
        "outputId": "02f9945a-08c8-4901-9232-49ecd5ff8c49"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    4776\n",
              "0.0    4776\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = keras.losses.BinaryCrossentropy()\n",
        "weights = -1\n",
        "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLJefiD10mhK",
        "outputId": "7e6e4da8-db61-49f8-cb3b-5b2dfa8edc7b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "299/299 [==============================] - 2s 3ms/step - loss: 4.4590 - accuracy: 0.8785\n",
            "Epoch 2/100\n",
            "299/299 [==============================] - 1s 4ms/step - loss: 0.0828 - accuracy: 0.9890\n",
            "Epoch 3/100\n",
            "299/299 [==============================] - 1s 5ms/step - loss: 0.0681 - accuracy: 0.9897\n",
            "Epoch 4/100\n",
            "299/299 [==============================] - 2s 7ms/step - loss: 0.0166 - accuracy: 0.9982\n",
            "Epoch 5/100\n",
            "299/299 [==============================] - 1s 5ms/step - loss: 0.0116 - accuracy: 0.9990\n",
            "Epoch 6/100\n",
            "299/299 [==============================] - 1s 4ms/step - loss: 0.0059 - accuracy: 0.9995\n",
            "Epoch 7/100\n",
            "299/299 [==============================] - 1s 3ms/step - loss: 0.0158 - accuracy: 0.9972\n",
            "Epoch 8/100\n",
            "299/299 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9994\n",
            "Epoch 9/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9997\n",
            "Epoch 10/100\n",
            "299/299 [==============================] - 1s 3ms/step - loss: 0.0033 - accuracy: 0.9998\n",
            "Epoch 11/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 0.9999\n",
            "Epoch 12/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.9999\n",
            "Epoch 13/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.9999\n",
            "Epoch 14/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9999\n",
            "Epoch 15/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9999\n",
            "Epoch 16/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 9.9579e-04 - accuracy: 0.9999\n",
            "Epoch 17/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 9.5489e-04 - accuracy: 0.9999\n",
            "Epoch 18/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.9937\n",
            "Epoch 19/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0081 - accuracy: 0.9991\n",
            "Epoch 20/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0014 - accuracy: 0.9998\n",
            "Epoch 21/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0013 - accuracy: 0.9999\n",
            "Epoch 22/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0012 - accuracy: 0.9999\n",
            "Epoch 23/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 0.9999\n",
            "Epoch 24/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9999\n",
            "Epoch 25/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9999\n",
            "Epoch 26/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 9.9100e-04 - accuracy: 0.9999\n",
            "Epoch 27/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 9.4680e-04 - accuracy: 0.9999\n",
            "Epoch 28/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 9.5069e-04 - accuracy: 0.9999\n",
            "Epoch 29/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 8.7114e-04 - accuracy: 0.9999\n",
            "Epoch 30/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 8.8644e-04 - accuracy: 0.9999\n",
            "Epoch 31/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 8.2866e-04 - accuracy: 0.9999\n",
            "Epoch 32/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0932 - accuracy: 0.9891\n",
            "Epoch 33/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 0.9998\n",
            "Epoch 34/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 0.9999\n",
            "Epoch 35/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 9.9631e-04 - accuracy: 0.9999\n",
            "Epoch 36/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 9.4875e-04 - accuracy: 0.9999\n",
            "Epoch 37/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 9.0801e-04 - accuracy: 0.9999\n",
            "Epoch 38/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 8.6567e-04 - accuracy: 0.9999\n",
            "Epoch 39/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 8.4254e-04 - accuracy: 0.9999\n",
            "Epoch 40/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 8.0624e-04 - accuracy: 0.9999\n",
            "Epoch 41/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 7.7362e-04 - accuracy: 0.9999\n",
            "Epoch 42/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 7.4649e-04 - accuracy: 0.9999\n",
            "Epoch 43/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 7.2036e-04 - accuracy: 0.9999\n",
            "Epoch 44/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 6.9722e-04 - accuracy: 0.9999\n",
            "Epoch 45/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 6.7885e-04 - accuracy: 0.9999\n",
            "Epoch 46/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 6.5381e-04 - accuracy: 0.9999\n",
            "Epoch 47/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 6.5886e-04 - accuracy: 0.9999\n",
            "Epoch 48/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 6.4639e-04 - accuracy: 0.9999\n",
            "Epoch 49/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 6.3385e-04 - accuracy: 0.9999\n",
            "Epoch 50/100\n",
            "299/299 [==============================] - 1s 3ms/step - loss: 5.7112e-04 - accuracy: 0.9999\n",
            "Epoch 51/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0792 - accuracy: 0.9938\n",
            "Epoch 52/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 9.6207e-04 - accuracy: 0.9999\n",
            "Epoch 53/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 8.9409e-04 - accuracy: 0.9999\n",
            "Epoch 54/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 8.4100e-04 - accuracy: 0.9999\n",
            "Epoch 55/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 7.8484e-04 - accuracy: 0.9999\n",
            "Epoch 56/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 7.2582e-04 - accuracy: 0.9999\n",
            "Epoch 57/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 6.7247e-04 - accuracy: 0.9999\n",
            "Epoch 58/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 5.8809e-04 - accuracy: 0.9999\n",
            "Epoch 59/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 5.3228e-04 - accuracy: 0.9999\n",
            "Epoch 60/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 4.9294e-04 - accuracy: 0.9999\n",
            "Epoch 61/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9965\n",
            "Epoch 62/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 6.7196e-04 - accuracy: 0.9998\n",
            "Epoch 63/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 4.1763e-04 - accuracy: 0.9999\n",
            "Epoch 64/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 3.9336e-04 - accuracy: 0.9999\n",
            "Epoch 65/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 3.8376e-04 - accuracy: 0.9999\n",
            "Epoch 66/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 3.6878e-04 - accuracy: 0.9999\n",
            "Epoch 67/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 3.7098e-04 - accuracy: 0.9999\n",
            "Epoch 68/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9959\n",
            "Epoch 69/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.1023 - accuracy: 0.9901\n",
            "Epoch 70/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9998\n",
            "Epoch 71/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 9.7166e-04 - accuracy: 0.9998\n",
            "Epoch 72/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 9.2295e-04 - accuracy: 0.9998\n",
            "Epoch 73/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 8.7521e-04 - accuracy: 0.9998\n",
            "Epoch 74/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 8.2426e-04 - accuracy: 0.9998\n",
            "Epoch 75/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 7.8462e-04 - accuracy: 0.9999\n",
            "Epoch 76/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 7.5385e-04 - accuracy: 0.9999\n",
            "Epoch 77/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 7.1995e-04 - accuracy: 0.9999\n",
            "Epoch 78/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 6.8108e-04 - accuracy: 0.9999\n",
            "Epoch 79/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 6.4358e-04 - accuracy: 0.9999\n",
            "Epoch 80/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 6.1344e-04 - accuracy: 0.9999\n",
            "Epoch 81/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 6.0196e-04 - accuracy: 0.9999\n",
            "Epoch 82/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 5.5564e-04 - accuracy: 0.9999\n",
            "Epoch 83/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 3.9611e-04 - accuracy: 0.9999\n",
            "Epoch 84/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 5.3877e-04 - accuracy: 0.9999\n",
            "Epoch 85/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 5.0132e-04 - accuracy: 0.9999\n",
            "Epoch 86/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 3.8055e-04 - accuracy: 0.9999\n",
            "Epoch 87/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 3.1094e-04 - accuracy: 0.9999\n",
            "Epoch 88/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 2.5494e-04 - accuracy: 0.9999\n",
            "Epoch 89/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.1127 - accuracy: 0.9894\n",
            "Epoch 90/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 6.9277e-04 - accuracy: 0.9999\n",
            "Epoch 91/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 6.4539e-04 - accuracy: 0.9999\n",
            "Epoch 92/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 6.0083e-04 - accuracy: 0.9999\n",
            "Epoch 93/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 5.5384e-04 - accuracy: 0.9999\n",
            "Epoch 94/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 5.0476e-04 - accuracy: 0.9999\n",
            "Epoch 95/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 4.5479e-04 - accuracy: 0.9999\n",
            "Epoch 96/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 4.1405e-04 - accuracy: 0.9999\n",
            "Epoch 97/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 3.6529e-04 - accuracy: 0.9999\n",
            "Epoch 98/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 3.1843e-04 - accuracy: 0.9999\n",
            "Epoch 99/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 2.8054e-04 - accuracy: 0.9999\n",
            "Epoch 100/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 2.5039e-04 - accuracy: 0.9999\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.9996\n",
            "[0.002405450912192464, 0.9995812177658081]\n",
            "75/75 [==============================] - 0s 1ms/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      1194\n",
            "         1.0       1.00      1.00      1.00      1194\n",
            "\n",
            "    accuracy                           1.00      2388\n",
            "   macro avg       1.00      1.00      1.00      2388\n",
            "weighted avg       1.00      1.00      1.00      2388\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Method-3: SMOTE**"
      ],
      "metadata": {
        "id": "pZ34nbIL-l18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To install imbalanced-learn library use **pip install imbalanced-learn** command"
      ],
      "metadata": {
        "id": "iEmmP37i-vKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULoMc75W8EFX",
        "outputId": "8360fb5b-c955-46b5-bf25-68d686e6fc7e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aaI3JmkD8JpS"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "X_sm, y_sm = SMOTE(k_neighbors=2,sampling_strategy='minority').fit_resample(X,y)\n",
        "\n",
        "y_sm.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFbMWjFd8Jkf",
        "outputId": "9be74d4d-f3c1-40da-937c-bbbadc77ef23"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    5970\n",
              "1.0    5970\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=15, stratify=y_sm)"
      ],
      "metadata": {
        "id": "e9iwhxzl8JgT"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of classes in training Data\n",
        "y_train.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssvGzoF28Jdo",
        "outputId": "7c9f24dd-dfb2-415f-e12f-b1b1bc38ed8e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    4776\n",
              "0.0    4776\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljaadchb8Jau",
        "outputId": "917286e5-29ef-4496-d1a5-6085a39afce6"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 3.3609 - accuracy: 0.8424\n",
            "Epoch 2/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0984 - accuracy: 0.9719\n",
            "Epoch 3/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.9693\n",
            "Epoch 4/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0194 - accuracy: 0.9981\n",
            "Epoch 5/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9984\n",
            "Epoch 6/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0150 - accuracy: 0.9982\n",
            "Epoch 7/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.9986\n",
            "Epoch 8/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0113 - accuracy: 0.9984\n",
            "Epoch 9/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.1070 - accuracy: 0.9785\n",
            "Epoch 10/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0073 - accuracy: 0.9990\n",
            "Epoch 11/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9991\n",
            "Epoch 12/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 0.9992\n",
            "Epoch 13/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.9994\n",
            "Epoch 14/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.9991\n",
            "Epoch 15/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.3793 - accuracy: 0.9714\n",
            "Epoch 16/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0068 - accuracy: 0.9991\n",
            "Epoch 17/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9995\n",
            "Epoch 18/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9993\n",
            "Epoch 19/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9996\n",
            "Epoch 20/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0359 - accuracy: 0.9927\n",
            "Epoch 21/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 0.9995\n",
            "Epoch 22/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.9994\n",
            "Epoch 23/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9993\n",
            "Epoch 24/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.9998\n",
            "Epoch 25/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.9998\n",
            "Epoch 26/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 0.9998\n",
            "Epoch 27/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.9998\n",
            "Epoch 28/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 0.9998\n",
            "Epoch 29/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.9997\n",
            "Epoch 30/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0349 - accuracy: 0.9952\n",
            "Epoch 31/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.9984\n",
            "Epoch 32/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 0.9997\n",
            "Epoch 33/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.9998\n",
            "Epoch 34/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.9998\n",
            "Epoch 35/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.9998\n",
            "Epoch 36/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 0.9998\n",
            "Epoch 37/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0023 - accuracy: 0.9998\n",
            "Epoch 38/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.9998\n",
            "Epoch 39/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.9998\n",
            "Epoch 40/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.9835\n",
            "Epoch 41/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0154 - accuracy: 0.9976\n",
            "Epoch 42/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0020 - accuracy: 0.9995\n",
            "Epoch 43/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9997\n",
            "Epoch 44/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9997\n",
            "Epoch 45/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 46/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.9998\n",
            "Epoch 47/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9998\n",
            "Epoch 48/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9998\n",
            "Epoch 49/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9998\n",
            "Epoch 50/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.9998\n",
            "Epoch 51/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0010 - accuracy: 0.9998\n",
            "Epoch 52/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 9.0105e-04 - accuracy: 0.9998\n",
            "Epoch 53/100\n",
            "299/299 [==============================] - 1s 3ms/step - loss: 8.8907e-04 - accuracy: 0.9998\n",
            "Epoch 54/100\n",
            "299/299 [==============================] - 1s 3ms/step - loss: 8.2677e-04 - accuracy: 0.9998\n",
            "Epoch 55/100\n",
            "299/299 [==============================] - 1s 3ms/step - loss: 7.9006e-04 - accuracy: 0.9998\n",
            "Epoch 56/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 6.8695e-04 - accuracy: 0.9998\n",
            "Epoch 57/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 6.9618e-04 - accuracy: 0.9999\n",
            "Epoch 58/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.1090 - accuracy: 0.9905\n",
            "Epoch 59/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9975\n",
            "Epoch 60/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 0.9998\n",
            "Epoch 61/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 9.0891e-04 - accuracy: 0.9998\n",
            "Epoch 62/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 8.0342e-04 - accuracy: 0.9998\n",
            "Epoch 63/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 6.7491e-04 - accuracy: 0.9999\n",
            "Epoch 64/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 5.9367e-04 - accuracy: 0.9999\n",
            "Epoch 65/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 5.3277e-04 - accuracy: 0.9999\n",
            "Epoch 66/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 4.7042e-04 - accuracy: 0.9999\n",
            "Epoch 67/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 4.1395e-04 - accuracy: 0.9999\n",
            "Epoch 68/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0014 - accuracy: 0.9996\n",
            "Epoch 69/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 6.5180e-04 - accuracy: 0.9998\n",
            "Epoch 70/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 4.1633e-04 - accuracy: 0.9999\n",
            "Epoch 71/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 3.7576e-04 - accuracy: 0.9999\n",
            "Epoch 72/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 3.2834e-04 - accuracy: 0.9999\n",
            "Epoch 73/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 2.4253e-04 - accuracy: 0.9999\n",
            "Epoch 74/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 2.6092e-04 - accuracy: 0.9999\n",
            "Epoch 75/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 2.2947e-04 - accuracy: 0.9999\n",
            "Epoch 76/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.9914\n",
            "Epoch 77/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 0.9994\n",
            "Epoch 78/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0020 - accuracy: 0.9997\n",
            "Epoch 79/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0018 - accuracy: 0.9998\n",
            "Epoch 80/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 81/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0013 - accuracy: 0.9998\n",
            "Epoch 82/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 0.9998\n",
            "Epoch 83/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 8.3261e-04 - accuracy: 0.9998\n",
            "Epoch 84/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 5.9569e-04 - accuracy: 0.9998\n",
            "Epoch 85/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 4.7231e-04 - accuracy: 0.9999\n",
            "Epoch 86/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 3.3844e-04 - accuracy: 0.9999\n",
            "Epoch 87/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 4.1665e-04 - accuracy: 0.9999\n",
            "Epoch 88/100\n",
            "299/299 [==============================] - 1s 3ms/step - loss: 2.2108e-04 - accuracy: 0.9999\n",
            "Epoch 89/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 1.7066e-04 - accuracy: 0.9999\n",
            "Epoch 90/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 1.5456e-04 - accuracy: 0.9999\n",
            "Epoch 91/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 1.4022e-04 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 1.2917e-04 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 1.1941e-04 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "299/299 [==============================] - 0s 2ms/step - loss: 1.0607e-04 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 1.0651e-04 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 9.6292e-05 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 8.7387e-05 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 6.6957e-05 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 7.4083e-05 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "299/299 [==============================] - 1s 2ms/step - loss: 6.3604e-05 - accuracy: 1.0000\n",
            "75/75 [==============================] - 0s 1ms/step - loss: 4.2541e-05 - accuracy: 1.0000\n",
            "[4.25405269197654e-05, 1.0]\n",
            "75/75 [==============================] - 0s 1ms/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      1194\n",
            "         1.0       1.00      1.00      1.00      1194\n",
            "\n",
            "    accuracy                           1.00      2388\n",
            "   macro avg       1.00      1.00      1.00      2388\n",
            "weighted avg       1.00      1.00      1.00      2388\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Method-4: Use of Ensemble with undersampling**"
      ],
      "metadata": {
        "id": "dIQC6g6GAKaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.Class.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT6tIp3i8JWQ",
        "outputId": "d486cc92-53c0-4331-e1da-d96094881d6d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    5970\n",
              "1.0       3\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=data.drop('Class',axis=1)\n",
        "y=data['Class']\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
      ],
      "metadata": {
        "id": "EurfkeyGAZcg"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmTuvlNhAZWl",
        "outputId": "dfcaa2b1-e319-4f78-e36f-8116b79bdf58"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    4776\n",
              "1.0       2\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here as the y dataset is too small if we divide the x in ratio of y then we have create total 2000 predictions and then combine then all , so because of this the method of ensaemble with undersampling is not preferred over here\n"
      ],
      "metadata": {
        "id": "pjoUu348Av79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So to conclude we can see that for the **credit card prediction model** to handle the skewdness (imbalance) data we can use **Oversampling** or **Smote method** and then use **ANN model** for classification "
      ],
      "metadata": {
        "id": "d6eNKAgGBk6q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QfDfNcjGBPPK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}